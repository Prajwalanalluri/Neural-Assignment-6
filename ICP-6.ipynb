{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Sqi2Scs3yme_slpmuzh1yVF8wwqY3HrF","authorship_tag":"ABX9TyO6tt8I/eCEWP5EgFp9NXDl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential, load_model\n","from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n","from matplotlib import pyplot\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","import re\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Load and preprocess data\n","data = pd.read_csv('/content/drive/MyDrive/Sentiment.csv')\n","data = data[['text', 'sentiment']]\n","data['text'] = data['text'].apply(lambda x: x.lower())\n","data['text'] = data['text'].apply(lambda x: re.sub('[^a-zA-Z0-9\\s]', '', x))\n","\n","for idx, row in data.iterrows():\n","    row[0] = row[0].replace('rt', ' ')\n","\n","# Tokenize and pad sequences\n","max_features = 2000\n","tokenizer = Tokenizer(num_words=max_features, split=' ')\n","tokenizer.fit_on_texts(data['text'].values)\n","X = tokenizer.texts_to_sequences(data['text'].values)\n","X = pad_sequences(X)\n","\n","# Encode labels\n","labelencoder = LabelEncoder()\n","integer_encoded = labelencoder.fit_transform(data['sentiment'])\n","y = to_categorical(integer_encoded)\n","\n","# Train-test split\n","X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n","\n","# Define and compile the model\n","embed_dim = 128\n","lstm_out = 196\n","\n","def create_model():\n","    model = Sequential()\n","    model.add(Embedding(max_features, embed_dim, input_length=X.shape[1]))\n","    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n","    model.add(Dense(3, activation='softmax'))\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    return model\n","\n","# Train the model\n","batch_size = 32\n","model = create_model()\n","model.fit(X_train, Y_train, epochs=1, batch_size=batch_size, verbose=2)\n","\n","# Evaluate the model\n","score, acc = model.evaluate(X_test, Y_test, verbose=2, batch_size=batch_size)\n","print(\"Score:\", score)\n","print(\"Accuracy:\", acc)\n","\n","# Save the model\n","model.save('model.keras')\n","\n","# Load the model for prediction\n","loaded_model = load_model('model.keras')\n","\n","# Preprocess new text data\n","new_text = [\"A lot of good things are happening. We are respected again throughout the world, and that's a great thing. @realDonaldTrump\"]\n","new_text = [re.sub('[^a-zA-Z0-9\\s]', '', x.lower()) for x in new_text]\n","new_seq = tokenizer.texts_to_sequences(new_text)\n","new_padded_seq = pad_sequences(new_seq, maxlen=X.shape[1])\n","\n","# Predict the sentiment\n","pred = loaded_model.predict(new_padded_seq)\n","print(\"Prediction:\", pred)\n","predicted_label = labelencoder.inverse_transform([pred.argmax(axis=1)[0]])\n","print(\"Predicted Sentiment:\", predicted_label)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3DxTvaXjyIu4","executionInfo":{"status":"ok","timestamp":1721691391218,"user_tz":300,"elapsed":96224,"user":{"displayName":"Prajwala Nalluri","userId":"04757928273236652738"}},"outputId":"3bae42a6-baf1-4245-82da-3b93a321db07"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["291/291 - 57s - loss: 0.8227 - accuracy: 0.6454 - 57s/epoch - 195ms/step\n","144/144 - 4s - loss: 0.7582 - accuracy: 0.6658 - 4s/epoch - 30ms/step\n","Score: 0.7582270503044128\n","Accuracy: 0.6657929420471191\n","1/1 [==============================] - 0s 276ms/step\n","Prediction: [[0.41744605 0.13247237 0.45008165]]\n","Predicted Sentiment: ['Positive']\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, LSTM\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","\n","print(tf.__version__)\n","\n","# Load and preprocess data\n","data = pd.read_csv('/content/drive/MyDrive/Sentiment.csv')\n","data = data[['text', 'sentiment']]\n","data['text'] = data['text'].apply(lambda x: x.lower())\n","data['text'] = data['text'].apply(lambda x: re.sub('[^a-zA-Z0-9\\s]', '', x))\n","data['text'] = data['text'].apply(lambda x: x.replace('rt', ' '))\n","\n","# Tokenize and pad sequences\n","max_features = 2000\n","tokenizer = Tokenizer(num_words=max_features, split=' ')\n","tokenizer.fit_on_texts(data['text'].values)\n","X = tokenizer.texts_to_sequences(data['text'].values)\n","X = pad_sequences(X)\n","\n","# Encode labels\n","labelencoder = LabelEncoder()\n","integer_encoded = labelencoder.fit_transform(data['sentiment'])\n","y = to_categorical(integer_encoded)\n","\n","# Train-test split\n","X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n","\n","# Define the model creation function\n","def create_model(embed_dim=128, lstm_out=196, dropout_rate=0.2, optimizer='adam'):\n","    model = Sequential()\n","    model.add(Embedding(input_dim=max_features, output_dim=embed_dim))\n","    model.add(LSTM(units=lstm_out, dropout=dropout_rate, recurrent_dropout=dropout_rate))\n","    model.add(Dense(units=y.shape[1], activation='softmax'))  # Use y.shape[1] for number of output units\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","\n","# Create and train the model\n","model = create_model()\n","model.fit(X_train, Y_train, batch_size=32, epochs=1, verbose=2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PW4fzSDZf0Tg","executionInfo":{"status":"ok","timestamp":1721703362331,"user_tz":300,"elapsed":44857,"user":{"displayName":"Prajwala Nalluri","userId":"04757928273236652738"}},"outputId":"ad9e9ae3-3c47-419d-8cbf-9393a2831979"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["2.17.0\n","291/291 - 29s - 98ms/step - accuracy: 0.6398 - loss: 0.8314\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7995babd0370>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from scikeras.wrappers import KerasClassifier\n","import tensorflow as tf\n","\n","print(tf.__version__)\n","\n","# Load and preprocess data\n","data = pd.read_csv('/content/drive/MyDrive/Sentiment.csv')\n","data = data[['text', 'sentiment']]\n","data['text'] = data['text'].apply(lambda x: x.lower())\n","data['text'] = data['text'].apply(lambda x: re.sub('[^a-zA-Z0-9\\s]', '', x))\n","data['text'] = data['text'].apply(lambda x: x.replace('rt', ' '))\n","\n","# Tokenize and pad sequences\n","max_features = 2000\n","tokenizer = Tokenizer(num_words=max_features, split=' ')\n","tokenizer.fit_on_texts(data['text'].values)\n","X = tokenizer.texts_to_sequences(data['text'].values)\n","X = pad_sequences(X)\n","\n","# Encode labels\n","labelencoder = LabelEncoder()\n","integer_encoded = labelencoder.fit_transform(data['sentiment'])\n","y = to_categorical(integer_encoded)\n","\n","# Train-test split\n","X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n","\n","# Define the model creation function using the Functional API\n","def create_model(embed_dim=128, lstm_out=196, dropout_rate=0.2, optimizer='adam'):\n","    inputs = Input(shape=(X.shape[1],))\n","    x = Embedding(input_dim=max_features, output_dim=embed_dim)(inputs)\n","    x = LSTM(units=lstm_out, dropout=dropout_rate, recurrent_dropout=dropout_rate)(x)\n","    outputs = Dense(units=y.shape[1], activation='softmax')(x)\n","\n","    model = Model(inputs=inputs, outputs=outputs)\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","\n","# Wrap the model using KerasClassifier from scikeras\n","model = KerasClassifier(model=create_model, verbose=2)\n","\n","# Define a parameter grid for tuning\n","param_grid = {\n","    'batch_size': [32],\n","    'epochs': [1],\n","    'model__embed_dim': [128],\n","    'model__lstm_out': [100],\n","    'model__dropout_rate': [0.2],\n","    'model__optimizer': ['adam']\n","}\n","\n","# Apply GridSearchCV with error_score='raise' for more details\n","grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, error_score='raise')\n","\n","try:\n","    grid_result = grid.fit(X_train, Y_train)\n","except ValueError as e:\n","    print(f\"An error occurred: {e}\")\n","\n","# If GridSearchCV succeeds, summarize results\n","if 'grid_result' in locals():\n","    print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n","    means = grid_result.cv_results_['mean_test_score']\n","    stds = grid_result.cv_results_['std_test_score']\n","    params = grid_result.cv_results_['params']\n","    for mean, stdev, param in zip(means, stds, params):\n","        print(f\"{mean} ({stdev}) with: {param}\")\n","\n","    # Evaluate the best model on the test set\n","    best_model = grid_result.best_estimator_\n","    score = best_model.score(X_test, Y_test)\n","    print(f\"Test Score: {score}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LcDyRMU9jAGI","executionInfo":{"status":"ok","timestamp":1721704804993,"user_tz":300,"elapsed":85606,"user":{"displayName":"Prajwala Nalluri","userId":"04757928273236652738"}},"outputId":"fd14ee37-ff43-4f60-a37d-4abc7b3a8054"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["2.17.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["291/291 - 17s - 57ms/step - accuracy: 0.6440 - loss: 0.8285\n","Best: 0.6643715684788774 using {'batch_size': 32, 'epochs': 1, 'model__dropout_rate': 0.2, 'model__embed_dim': 128, 'model__lstm_out': 100, 'model__optimizer': 'adam'}\n","0.6643715684788774 (0.003644225243254965) with: {'batch_size': 32, 'epochs': 1, 'model__dropout_rate': 0.2, 'model__embed_dim': 128, 'model__lstm_out': 100, 'model__optimizer': 'adam'}\n","144/144 - 4s - 28ms/step\n","Test Score: 0.6721275666229795\n"]}]}]}